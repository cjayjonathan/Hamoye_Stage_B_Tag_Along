{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cjayjonathan/Hamoye_Stage_B_Tag_Along/blob/main/ML_Regression_Predicting_Energy_Efficiency_of_Buildings_Hamoye_Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple linear regression model estimates the relationship between two quantitative variables where one is referred to as the independent variable and the other the dependent variable. The independent variable (X) is used to predict and also called the predictor while the predicted variable is referred to as the response variable (Y) (e.g. finding the relationship between the amount of CO2 gas emitted and the number of trees cut down). The value of Y can be obtained from X by finding the line of best fit (regression line) with minimum error for the data points on a scatter plot for both variables.\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XDUb3J_pBv7Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "xHTB-SY80GRA",
        "outputId": "397bf2f2-c810-44a1-8160-584e509e7cfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6d091e8590>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEHCAYAAABGNUbLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xcZ3Xo/d+ai+6SdbFkTXyJ49wc21IDOAESMCYhVxkKHF4aCjQceEnop7S0FAq07xs4oX0PPaWFnHP66YkpbdKWknItwXJuxDiGEJLYuUi248SJnMRORhdbknWZ+8x6/9h7pLGRbY01o7mt7+ejj2aemT372dZ4zTPPfvZaoqoYY4ypLJ5Cd8AYY8zis+BvjDEVyIK/McZUIAv+xhhTgSz4G2NMBfIVugPztXTpUl29enWhu2GMMSVlz549R1W1/eT2kgn+q1evZvfu3YXuhjHGlBQReWWudpv2McaYCmTB3xhjKpAFf2OMqUAW/I0xpgJZ8DfGmApUMqt9jDG/aeeBYe7cNcDhsRArW+q4ddMaNq/tKHS3TAmwkb8xJWrngWFuu3cfw5MRmmv9DE9GuO3efew8MFzorpkSYMHfmBJ1564B/F6hrsqHiPPb7xXu3DVQ6K6ZEmDB35gSdXgsRK3fe0Jbrd/LkbFQgXpkSokFf2NK1MqWOsLx5Alt4XiSFS11BeqRKSUW/I0pUbduWkM8qYRiCVSd3/GkcuumNYXumikBFvyNKVGb13Zw+3vW09FYw/FwnI7GGm5/z3pb7WPmxZZ6GlPCNq/tsGBvzoqN/I0xpgJZ8DfGmApkwd8YYyqQBX9jjKlAFvyNMaYCWfA3xpgKtCjBX0S8IvK0iGxz798lIodE5Bn359LF6IcxxhjHYq3z/wzwHNCU0fZ5Vf3BIu3fGGNKTjKlJFIpqn3eMz85S3kf+YvICqAH+Md878sYY8rF8XCcI2MhIrFUXl5/MaZ9vgn8GXDyEfyViPSJyDdEpHquDUXkFhHZLSK7R0ZG8t5RY4wptEg8yZGxEMemoiRTmrf95DX4i8gWYFhV95z00JeAtcBlQCvwhbm2V9WtqrpRVTe2t7fns6vGGFNQiWSK4YkIr4+HiSXyM9rPlO85/yuB94jIjUAN0CQi/6aqH3Efj4rIPwOfy3M/jDGmKCVTyvFwnOPhOKr5G+mfLK8jf1X9kqquUNXVwE3ADlX9iIgEAEREgPcCe/PZD2OMKTaqyngoxuHREOOh2KIGfihcVs/viEg7IMAzwKcK1A9jjFlUqspEJMHxUJxEKv/TO6eyaMFfVXcCO93bVy3Wfo0xplhMRROMTceIJwsX9NMsn78xJWzngWHu3DXA4bEQK1vquHXTGsvvX4Qi8SSj0zEiJ5XdLCRL72BMidp5YJjb7t3H8GSE5lo/w5MRbrt3HzsPDBe6a8aVTCkjk1FeHw8XVeAHC/7GlKw7dw3g9wp1VT5EnN9+r3DnroFCd80AExHnIq3JSLzQXZmTTfsYU6IOj4VorvWf0Fbr93JkLFSgHhmAaCLJ0akY0SIb6Z/MRv7GlKiVLXWETwow4XiSFS11BepRZUullGNTUV4bCxd94AcL/saUrFs3rSGeVEKxBKrO73hSuXXTmkJ3reJMRRMcGQtzPFycUzxzsWkfY0rU5rUd3I4z939kLMQKW+2z6GKJFMemo4RjxT/SP5kFf2NK2Oa1HRbsC8C5OjfO+CKnZMglC/7GGJOF6WiC0SK5UGshLPgbY8w8TEcTjIVii5JxczFY8DfGmFNQVaaiCY6H42UT9NMs+BtjzEmKJflaPlnwN8aYDOUyp38mFvyNMYbiTL6WTxb8jTEVLZZIMRaKMR1NFLori8qCvzGmIsWTTtCfilRW0E9blPQOIuIVkadFZJt7/zwReVxEXhSR/xCRqsXohzHGxJMpRiajHBkLV2zgh8XL7fMZ4LmM+38NfENVLwDGgE8sUj+MMRUqkRH0JyOle2VuruQ9+IvICqAH+Ef3vgBXAT9wn3I3ThF3Y4zJuUQyxdGpKIct6J9gMeb8vwn8GdDo3m8DxlU1/X3rCLB8EfphjKkgiWSK8XCcyUjCAv4c8jryF5EtwLCq7jnL7W8Rkd0isntkZCTHvTPGlKOkm1f/8FiYiRJOvJZv+R75Xwm8R0RuBGqAJuAOoFlEfO7ofwXw2lwbq+pWYCvAxo0b7S9ojDklVeV4OM54KE7KAv4Z5XXkr6pfUtUVqroauAnYoaofBn4OfMB92s3AT/LZD2NMeZt2i6mMTscs8M9ToSp5fQH4rIi8iHMO4NsF6ocxpoTFEikGj0cYmoiUfTqGXFu0i7xUdSew0709AFy+WPs2xpSXVEoZC8WYsJO5Z82u8DXGlAxVZSKcYDwcI5myoL8QFvyNMUVPVZmMJhifLt8Uy4vNgr8xpmilg/7xUNzm9HPMgr8xpihVSl79QrHgb4wpKpWWV79QLPgbY4pCPJlibDrGVIXl1S8UC/7GmIKyZZuFYcHfGFMQtmyzsCz4G2MWnZ3Mnb/R6RjVfg81fm9OX9eCvzFm0djJ3PlJqfL0q+Ns6wvy6ItH+f/e38UHN67M6T4s+Btj8i6aSDIeildckfRsHZuK8sC+IXr7gwSPR2baf/rs6xb8jTGlI5pIcjwUL5oVPE8MjHLPk4cJToQJNNVy02UruXxNa0H7lEwpu18ZpbdvkF+9dJTM0x9dy5fwO5et5ANvWpHz/VrwN8bkXCiW4Hg4TjhWPNM7TwyMcseOg/g8QlONj2PTUe7YcZDPcGFBPgBGJqPctzfI9v5BhiejM+1NNT6uW9/JjV2dnNtWT1t9dc7n+8GCvzEmR2KJFFPRBFORRFHm37nnycP4PEKtG0hr/V7C8ST3PHl40YJ/MqU8fugY2/qCPHFo9IRR/qUrm9nSHeBtFyylypf/bPsW/I0xC1KMo/y5BCfCNNWcGPJq/B4GJ8J53/fg8Qjb9wa5f+8gR6diM+0tdX6uW99JT1eA5S21ee9HJgv+xpizMh1NMBaKEUsU3yh/LoGmWo5NR2dG/gCReIrOpvwE3UQyxa8GjtHbF2T3y2OkB/kCvOncFrZ0B3jr+W34vYWpqWXB3xiTlUg8ybHpGNESW65502UruWPHQcLxJDV+D5F4ikRKuemy3K6ieW08zPZ+Z5Q/ForPtLfVV3H9BmcuP7BkcUf5c8lr8BeRGmAXUO3u6weq+mURuQt4B3DcferHVPWZfPbFGLMw0USSsek4oVhxrNzJ1uVrWvkMF3LPk4cZnAjTmcPVPrFEikdfPEpvf5CnXh2fafcIXLa6lZ4uZ5Tv9ciC95Ur+R75R4GrVHVKRPzAL0XkPvexz6vqD/K8f2PMAsWTKcZCMaYipRn0M12+pjWnJ3dfHQ3R2xfkwf1DHA/PjvLbG6q5oauTGzd00tFUk7P95VJeg786WZqm3Lt+98eSeBhTApIpZdwSrv2GWCLFroMj9PYFefbI8Zl2j8Bb1rSxpTvAZatbi2qUP5e8z/mLiBfYA1wA/L2qPi4ivw/8lYjcBjwMfFFVo6d7HWPM4killIlInPFQnJQF/RmHjk7T2x/kof1DTGZ8C+psquHGrk6u39DJ0obqAvYwO3kP/qqaBC4VkWbgxyKyAfgSMAhUAVuBLwC3n7ytiNwC3AKwatWqfHfVmIqmqkxEnJKJxbhOvxAi8SQ7nx+htz/IvtcnZtq9HuHKC9ro6QrwpnNb8Ehxj/LnsmirfVR1XER+Dlyvql93m6Mi8s/A506xzVacDwc2btxoQxBj8mQqmmDMsmzOeGl4im19QX52YIjp6OyqpuXNtfR0dXLt+k5a66sK2MOFy/dqn3Yg7gb+WuAa4K9FJKCqQRER4L3A3nz2wxgzt1JdtpkPoViCHQecUf7zg5Mz7X6v8LYLltLTHeANK5uREhzlz+WMwV9E3n+6x1X1R6d5OADc7c77e4Dvqeo2EdnhfjAI8AzwqSz6bIxZoFJftpkrqsoLQ84of8eBYcIZH4KrWuucUf66TpbU+QvYy/yYz8j/3e7vDuAKYId7/53Ar4BTBn9V7QPeMEf7Vdl10xiTC+FYkuNhC/pT0QQPPzdMb1+QF0emZtqrfB42XbiUd3efw4blTWUzyp/LGYO/qv5XABF5EFinqkH3fgC4K6+9M8YsmKoyGXVO5FbynL6qsj84QW/fIDufHyaSkZZizdJ6buwKcM26DhprimOUn04/PTwZ4dy2em7dtIbNazty9vrZzPmvTAd+1xBgS3CMKWKT7pLNSg76k5E4D+0ford/kENHp2faa3we3rm2g56uAJcEGotqlJ+ZfnpJrZ/hyQi33buP2yFnHwDZBP+HReQB4Lvu/d8BfpaTXhhjciaZUiYjcSYjiYoN+qpK/2vH6e0f5JEXRk5IPndBRwM9XQGuvqSDhuriTG+WmX5aRKir8hGKJbhz18DiB39V/bR78vftbtNWVf1xTnphjFmwaMKZz5+OJiv2itzjoTgP7h+kt3+QV0dDM+21fi9XX9LBlu4AFy1rLGAP52eu9NO1fi9HxkKn2CJ7WX3suSt7Tre6xxizyCr9JG5KlWcOj9PbF+SXLx4lnpz94Lu4s5EtXQGuWttBbVXuq2Hly1zpp8PxJCta6nK2j3kHfxF5C/C/gEtwrsz1AtOq2pSz3hhj5iWZUqYiCSYilTufPzod44F9g2zvH+S18dmCLPVVXt61bhlbugKc39FQwB6evcz00w0eIRRLEk8qt25ak7N9ZDPy/9/ATcD3gY3A7wEX5awnxpgzSiRTHA878/mVmHcnpcqeV8bo7Qvy6EvHSGbUQVx/ThNbugO846L2vNS8XUyZ6adHJiOsKvBqH1T1RRHxuvl6/llEnsbJ02OMyaNEMsVYKM5UtDIzbB6dinL/XmeUPzgRmWlvrPFxzbpl9HQFOG9pfQF7mHvp9NNt9dV5ucgsm+AfEpEq4BkR+R9AEOeqXWNMnqRSyng4zvFwvOKCfjKlPPnyKNv6gvx64NgJxc5/a8USeroDbLqwfVGKnZejbIL/R3GC/aeBPwFWAv8lH50yxjhXoY5OxSouw+bwRITtewe5r3+QkanZTO9Lav1c647yV7Xl7sRnpcpmqecr7sh/FfBD4HlVjZ9hM2NMlhLJFEenYhW1eieRTPHrgVF6+4M8cWj0hIpPb1zVzJbuAFecv7TiRvlej+Dz5ufis2xW+2wG7gZexknItlJEblbVXXnpmTEVJhxLMhmNE4omK+ZkbvB4mO39g9y/d5Bj07GZ9pY6Pzds6OSGrgDLm3NX7DydMiE4ESaQwxq+ueT1OBd1NVT7qPF78nblcTbTPn8LXKuqzwOIyEU4V/u+KR8dM6YSVGIBlXgyxa9eOsa2viB7XhmbaRdg4+oWtnSfw1vXtOLz5naUn5kyoanGx7HpKHfsOMhnuLDgHwCZAX+xrkfIJvj704EfQFVfcIuyG2POQqUVUDkyFmJ7/yAP7BtkLDQ7Y9zWUMWNGzq5YUOAziX5K3aemTIBnCtmw/Ek9zx5uCDB3+fxUFftpb5q8QL+CfvP4rm7ReQfgX9z738Y2J37LhlT3sKxJKOhyiigEkuk+OWLR9nWF+SZw+Mz7R6BN5/XRk93J28+r21Rip3PlTKhxu9hcCJ8ii1yz+/1zIzuC30tQjbB//eBPwD+yL3/C+Dvc94jY8pUJRVQeeWYU+z8wX1DTGQUO+9orKanK8D1Gzppb1zcYudzpUyIxFN0NuXunMJc0gG/vtpXVCess1ntEwX+zv0BQEQeBa7MQ7+MKRuVEvSj8SSPHDxKb9/r9L82W+zcI3DF+UvZ0u0UO1+MUf5cMlMm1Pg9ROIpEinlpstW5nxffq+HuiovDTU+qn3FebXxQvOZnjafv4jUALuAandfP1DVL4vIecA9QBuwB/ioqsZO/UrGlJ5YIsVYKMZ0tLyD/sDIFL39gzy0f4ipjGMNLKmZGeUXQ7HzzJQJgxNhOnO82icd8OurfQWf0pmPhQb/M61HiwJXqeqUe3L4lyJyH/BZ4Buqeo+I/B/gE8A/LLAvxhSFeNIJ+lOR8g364XiSnQeG6e0Psj84W+zc58kodr6qGU8RFUiB2ZQJueL3eqiv9lFXBHP42VpIAXcBTjtZps716OkCmX73R4GrgN912+8GvoIFf1PiYokU4+FYWefTPzg0ybb+IA8/N0woNnvCekVLLT1dAa5bv4zmusKP8k8lF+v80wG/vtpbtFM685FNAfe5bDvTxiLixZnauQDnBPFLwLiqpodFR4Dl8+iHMUUpEk8XUSnPkX4olmDHgWG29QV5YWi22LnfK2y6sJ0t3QG6VywpqjKIc1nIOv/0Sdu6Eg/4meZdwP1M3Kt9755j+yRwqYg0Az8G1s63cyJyC3ALwKpVVi7YFJdQLMFYKF6WSzZVlQODk/T2B9lxYJhIfPZahHNb6+jpDnDNumUsqS2dS32yXedf7fdSX+Wlrqq4VunkSi4LWH4GZwpnTqo6LiI/B94KNIuIzx39rwBeO8U2W4GtABs3bizP79Gm5JTzOv2pSIKfPTdEb3+Ql0Zmi51X+TxsvsgZ5a8/p6noR/lzOdM6fxHng6Gu2kud35vzK4yLTS6D/2+8G0SkHYi7gb8WuAb4a+DnwAdwVvzcDPwkh/0wJi/CsSRjoRiRMgv6qsq+1yfo7Q+y8/kRohnFztcsraenO8C7LumgsaZ0RvlzmWudfzSRYnlzHR1NNdT5vXgKtAy1EHIZ/OcamQeAu915fw/wPVXdJiL7gXtE5C+Bp4Fv57AfxuRUuQb9iXCch54borcvyMvHZguD1/g9XHVxBz3dAdZ2NpbkKH8umev866q8xJIpVOEPr7qAhupchsLSkNeRv6r2AW+Yo30AuDyH+zYm56ajCcbD5TWnr6r0HTlOb3+QR14YOaHY+YUdDfR0B7h6bQf1ZRgM335xO021Pv7lsVd4bTzMipa6nJdGLCW5/As/msPXMqYgookkoWiSqWiirBKujYdiPLBviO39QQ6PzeayqavycvVaZ5R/0bLGAvYwP6r9XhqqnFU6fq+H5c213Nh9TqG7VRSyyef/2TmajwN7VPUZVf107rplzOJRVSajTlrlcgr4KVWefnWc3r4gv3zxKImMOohrOxvZ0h3gnRd3FCSjZD6dHPDN3LIZ+W90f37q3t8C9AGfEpHvq+r/yHXnjMmnVEqZjCQ4Hi6vXPqj0zHu3ztIb3+Q4PHZYuf11V6uuWQZPd0Bzm9vKGAPc88CfvayCf4rgDeq6hSAiHwZ6AU24VzEZcHflIRkSpkIx5mIxEmmymMFcTKl7HlljG19QR4bOHbCcXUtb6KnK8Cmi9pLLgXB6dT4nTw69VXlvywzH7IJ/h04uXrS4sAyVQ2LSPQU2xhTNCLxJBOReFmlXxiZjHL/3kG27w0yNDH737Cpxse1651i5+e21Rewh7lV6150ZQF/4bIJ/t8BHheR9Jr8dwP/LiL1wP6c98yYHIglUoRiCaaiCWKJ8pjaSaaUxw8do7dvkMcPHSPzy8ulK5fQ03UOb7+wfIqd11alR/i+gqWDLkfZ5PP/qojcD1zhNn1KVdOVvD6c854Zc5bSdXEnwuV1AndwIsL9/c4o/+jUbAb05lo/12/o5MauTla01BWwh7mReaWtBfz8yXap51M4qRh8ACKySlVfzXmvjDkLqspEuLxO4CaSKR4bGKW373WefHnshCsp33RuC1u6A1xxflvJn+T0iFBX5aWu2ldxV9oWSjZLPf8Q+DIwBCRxLupSoDs/XTNmfhLJFMfDcaaiibI5gfvaeJjt/UEe2DfE6PTsKL+1voobNnRyw4ZOzmnOb/nBfEsXP6mr8lHj95TNlcSlIpuR/2eAi1X1WL46Y0w2QrEEk5FE2aRSjidTPOoWO3/q1dli5wJcdl4rW7oCvGVNa0mf6Cy1alflLJvgfxjnoi5jCiaZUiYjcSYj5XMF7uHREL3uKP94OD7T3t5QzQ0bOrm+q5POppoC9nBhPCLUV/torLGAX0yyCf4DwE4R6SVjyaeq/t2pNzEmN2KJFBOROFORBKkyWKYZS6T4xcERtvUFefbI7JjKI/CWNW30dAW4/LzWkj3Z6RGZOWFbV+W1KZ0ilE3wf9X9qXJ/jMm7UCzBRDhBKFYeUzuHjk7T2x/kZ/uHmMio8busqZobuwJcv76T9sbqAvbw7Hk94qzBr/ZS67eAX+yyWer53/LZEWPSIvEk09EEoViyLKZ2IvEkj7wwQm9fkL2vT8y0ez3Clee30dMd4E3nthRdsfP5SE/pNFT7yi5HULmbTwH3b6rqH4vIT5kjZ7+qvicvPTMVJZ1nZyJSPmvzXxqeYlt/kJ89N8R0dDYt9DnNNdy4IcD1GzpprS+9L9HpKZ2Gap+N8EvYfEb+/+r+/no+O2IqUySenFmxUw5z+eFYkh0HhuntD3JgcHKm3ecR3n7hUnq6Aly6qrnkRvnpdfj11TaHXy7mU8B9j/v7kfx3x1SC9MVY5TTKf2Fokm19QR5+bphwRvGXFS219HQFuG79MprrSmuUP5+TtjsPDHPnrgEOj4VYWeHFUUrNfKZ9+pm7RKMAqqqnvMhLRFYC/wIsc19jq6reISJfAT4JjLhP/XNV3Z5l300JmojEGZ8ujytwp6MJHj4wzLa+IC8OT820+73COy5qp6c7QPfyJSU1ShYR6qu8NNSceUpn54Fhbrt3H36v0FzrZ3gywm337uN2sA+AEjCfaZ8tC3j9BPCnqvqUiDQCe0TkIfexb6iqTSVVgGgiyXTUOYlb6iN9VeW54CS9/UF+fmCYSEayuNVtdWzpDvCuS5bRVFtaxc5r/E7Ab6jyzTu1wp27BvB7nRU+AHVVPkKxBHfuGrDgXwLmM+3zSvq2iCwDLnPvPqGqw2fYNggE3duTIvIcsPzsu2tKRSSeJBQrj4APMBmJ89D+Ybb3Bxk4Oj3TXu3zsPnidrZ0B1gXaCqpUb7f66Gh2kdDje+scgMdHgvRfNKHXK3fy5Gx0Cm2MMUkm9w+HwT+BtiJM+Xzv0Tk86r6g3luvxqnmPvjwJXAp0Xk94DdON8OxrLquSk65VYOUVXZ+9oE29xi55kpoc9vr2dLd4Cr1y6joaZ0ip37vR4nPXK1l2rfwpZmrmyp49DRKSYjCWLJFFVeD401Ps5bWl5VwspVNu/avwAuS4/2RaQd+BlwxuAvIg3AD4E/VtUJEfkH4Ks45wG+Cvwt8PE5trsFuAVg1apVWXTVLKZUajbol8Nc/vFwnAf3D7G9L8gro7Oj2Bq/h6vXLqOnu5OLlzWWzCg/ffFVrtMrvHVNK0+8PIpHnCuTY8kUI1Mxfvfy1pztw+RPNsHfc9I0zzHgjN8VRcSPE/i/o6o/AlDVoYzHvwVsm2tbVd0KbAXYuHFj6a8DLCOqSiiWZMq9GKvUK2OpKs8cHqe3f5BfHBwhnpw9nouXNdLTHeCqte0z89vFbjHW4j82MEpHYxUT4dmRf1Otj8cGRvmjnO/N5Fo27+T7ReQB4Lvu/d8BTrtCR5x33LeB5zJzAIlIwD0fAPA+YG8W/TAFlE6sNhFOlMUofywU44G9g2zfO8iRsfBMe32Vl6svWUZPVycXLmssYA/nTzLW4tcvwlr8w2Mh2uqrWdowm3ROVW3Ov0Rkk97h8yLyfuBtbtNWVf3xGTa7Evgo0C8iz7htfw58SEQuxZn2eRm4Natem0VXTvVvU6o89coY2/qD/OrFYyQyagCsCzSxpTvAOy5up7ZEMlDWVjkj/PosVurkwsqWOoYnIyd8GwrHk2VRTawSZPsd9lGcwu0KPHGmJ6vqL3FODp/M1vSXgEQyxXQsyWQkXhb1b49NRbl/3yDb+wcJHo/MtDdU+7h23TJ6ugOct7Q0ip373ZOrDdW+guX3v3XTGm67dx+hWIJav5dwPEk8qdy6aU1B+mOys2irfUxpSKaU6ViCqUiCSMaVqqUqmVKefHmU3v4gj710YrHzruVL2NIdYNOFS6kugVG+z+OhvtpZj7/QlTq5sHltB7fjrPc/MhZihV3hW1IWZbWPKW6qylQ0wVQ0QSSeKvlpHYDhiQj37R3kvr2DDE/OlJ+gqcbHdes76ekKsKqt+Kcn0iduG6v9RZk1c/PaDgv2JSrvq31M8YomkkyEyyepWjKl/HrgGL39QZ44NHrCKP/Slc28uzvAlRcspcpX/G/bdF78hmpfySwpNaUlr6t9TPFJj/InIgmiZTCtAzB4PEJvf5D79w1ybGq22HlLnX9mlL+8pfiLnVf5PDRW+6mv9pZ0nV5TGuaT2O0CYNkcq30eA76Tz86Z3EkkU0xEEkxG4iRTpT/KTyRT/OolZ5S/++WxmcyDAmxc3UJPV4C3nt92VmkLFlOxzeObyjGfkf83gS8BuBdp/QhARLrcx96dt96ZBcm8EGs6Wh5lEF8bC7vFzgcZC80WO2+rr+L6DZ3c2NVJYElxj/IzL8AqlYvGTPmZzztvmar2n9yoqv1uvh5TZCLx2YBfDqP8WCLFoy8eZVt/kKdfHZ9p9whcfl4rPV0B3rKmreiLnddVOUnUFuMCLGPOZD7Bv/k0jxX3EKuCxJMppiLOip1ySKoG8Oqx0MwoP7PYeUdjNTds6OSGDZ10NNWc5hUKrxjW4xszl/kE/90i8klV/VZmo4j838Ce/HTLzEcqpUyV0Zp8gGg8ySMHj9LbF6T/teMz7R6Bt65xip1ftrq1qEf56YIojTXFuTzTGJhf8P9j4Mci8mFmg/1GoAonL49ZRKpKOJ5kKpJgugwSqqUdOjpNb1+QB/cPMZVxfqKzqYae7k6uW9/J0obqAvbwzKp8Hhpr/DRU+4r6w8kYmF8xlyHgChF5J7DBbe5V1R157Zk5QbnN44OTB2bn8yP09gXZH5yYafd6hCsvaKOnK8Cbzm0p6mLnHhHqq3OfLtmYfMsmsdvPgZ/nsS/mJIlkiqlogslI+czjA7w4POUWOx9iOjY7XbW8uZaerk6uXd9Ja31xFzuv9nudufxFTqZmTK7YOrMik0rn1okmCMfKYx4fIBRLsOPAML19gzw/NDnT7vcKb7+wnZ6uTi5d2VzUq2A8IjTUOKN8W5NvSp0F/yJRbqkWwDk/8fzQJNv6glCdHVUAABalSURBVOw4MEwkPvvtZVVrnTPKX9fJkrriLnZe7ffS5K7YKeYPJ2OyYcG/wEKxBOOheNms1gGYiiZ4+LkhtvUFeWlktth5lc/DOy5qZ0tXgA3Li7vYudcjNFT7aKzxl0QuIGOyZcG/AFSV6ViS8VCsLPLkg3NM+16foLc/yM7nR4hmHNeapfX0dAd41yUdNNYU9yg/Xeu2zi7EMmXOgv8iKscVOxPhOA89N0RvX5CXj2UUO/d5eOfaDnq6AlwSKO5i536vxx3l24VYpnLkNfiLyErgX4BlONW/tqrqHSLSCvwHsBqnjOMHVXUsn30plHJcsaOq9L12nN6+II+8cGKx8ws6GtjSHeDqtR3UVxfv2CJ9IVZDjeXXMZUp3+/6BPCnqvqUiDQCe0TkIeBjwMOq+jUR+SLwReALee7LoklXw5ousxU746EYD+53RvmHM4qd1/q9XH1JB1u6A1xU5MXObYmmMY68Bn9VDQJB9/akiDwHLAd+G9jsPu1unNKQJR/8wzGnyHmojK68TanyzKvj9PYH+cXBoycUO1/b2ciW7gDvvLijqNMY2BJNY37Ton3fdTOAvgF4HCdTaNB9aBBnWmiubW4BbgFYtWpV/jt5FlIpZTKaYCIcL5tpHYDR6Rj37x1k+94gr4/PFjuvr/byrkuWsaUrwPkdDQXs4ZnVuvl1LIumMb9pUYK/iDQAPwT+WFUnMv8jqqqKyJzDZFXdCmwF2LhxY1ENpWOJFBOROFOR8lmXn1JlzytjbOsL8quXjp1wUnr9OU1s6Q7wjovaizqNQXqJZlOtv+gLuRhTSHkP/iLixwn833GLwQAMiUhAVYMiEgCGT/0KxSORTDEdTTIZjZfNEk2Akcko9+8bZHt/kKGJ2WLnjTU+rl23jBu7Apy3tL6APTw9EaHW77Vc+cZkId+rfQT4NvCcqv5dxkP3AjcDX3N//ySf/ViIZEpnlmeW04VYyZTyxKFRevuD/Hrg2AnFzn9rxRJ6ugNsurC9qC9wqvY71bAsi6Yx2cv3yP9K4KNAv4g847b9OU7Q/56IfAJ4BfhgnvuRlVgiRSjmpEwulyLnaUMTEe7rH+S+vYOMTM2O8pfU+rluvTPKX9VaV8Aenl56Wsdq3hqzMPle7fNLnJrac7k6n/vOhqoSiaeYjjlLM8vpxC0401WPDTij/CcPjZJ5huJNq5rp6T6HKy8o7mLnVgLRmNyq2Ktb0tM54ViScLx8lmZmen08zPb+IPfvG2J0OjbT3lpfxfXrl3FDV4DlzcVbidNO3hqTPxUV/NM5daYiCUKxxJk3KEHxZIpHXzxGb9/r7Mkodi7AZW6x87euaS3qNAZ+r4emWj9NNZZF05h8qYjgH445K3RC0WTZLMs82eHRENv7gzywb4jxcHymfWlDFTduCHB9VyedRVzsXESoq/K6SdUq4m1pTEFVxP+y4clISSRSe2JglHuePExwIkygqZabLlvJ5WtaT/n8WCLFLw6O0Nsf5JnDJxY7f/N5bfR0d/Lm89qKeiWM3+tx0i1UW1I1YxZTRQT/UvDEwCh37DiIzyM01fg4Nh3ljh0H+QwX/sYHwMvHnGLnD+0fYiIyO33V0VhNT1eA6zd00t5YvMXO00nVGmv8RZ0WwphyZsG/SNzz5GF8HudiJXCSpYXjSe558jCXr2klEk+y64URtvUF2fv6icXO37qmjS3dTrHzYh/lN9X4aaixdfnGFFpZB/+dB4a5c9cAh45O0TmPaZRCCk6Eaao58c9R4/dweGya//nwQR56bojp6Ow1B4ElNTOj/GIvdl5X5WNJbWFH+en3wuGxECtb6rh10xo2r+0oWH+MKbSyDf47Dwxz27378HuFxhr/aadRikGgqZZj01Fq/d6ZZHFjoRixpPKfz7wOgM8jvO2CpfR0B3jDqmY8RbwSRsRZprmktvBlEDPfC821foYnI9x27z5uB/sAMBWrbIP/nbsG8HuFuiof0UTyN6ZRis1Nl63k6w89z+h0jHA8eUK6hRUttfR0Bbhu/TKa64p7lO8RoanWz5Jaf9FM7WS+F8D5JhKKJbhz14AFf1Oxyjb4Hx4L0Vx7Yr3YGr+HwYnwKbYojOlogh0HhtnWF+To1OyFWIKTY+fmK1bTvWJJ0a9393k8LKn101hTfEVS5nov1Pq9HBkLnWILY8pf2Qb/lS11DE9GTlgzHomn6Gwq/BWtqsqBwUl6+4LseH6YSHw2ncS5bXVs6Q5wzSXLaKot7mLnADV+L021xZ0zf673QjieZEVL8eYwMibfyjb437ppDbfdu49QLIFHhEg8SSKl3HTZyoL1aSqSmCl2PnB0eqa92udh88Xt9HQFWH9OU9EG0bT0fH5jja+oc/unZb4X0tN/8aRy66Y1he6aMQVTtsF/89oObseZ73356BTLCrTaR1XZ+9oEvf1Bdr4wckIdgDXt9by7O8DVa5fRUFP8f4oqn4fGGj+N1cU3tXM6me+FI2MhVthqH2OQUklotnHjRt29e/dZbfvKselFv8L3eDjOg/uH2N4X5JXR2bnlGr+Hq9Z20NMVYG1nY9GP8j0i1JfQKN8YcyIR2aOqG09uL/7hZglRVfqOHGdbX5BdB0eIJ2c/cC5a1kBPV4CrL+koidw16eRqpTbKN8bMT/FHoRIwForxwL4htvcHOTI2u5qorsrL1Zc4o/yLljUWsIfzV1vlZUmtvyQ+oIwxZ8/+h5+llCpPvTJGb/8gj754lETGtNIlgUa2dAXYvLZjJl1DMRMR6qudoG/VsYypDPmu4ftPwBZgWFU3uG1fAT4JjLhP+3NV3Z7PfuTSsal0sfNBgscjM+0N1T6uWbeMnq5O1rQ3FLCH8+fzeGiq9dFYUzwXZBljFke+R/53Af8b+JeT2r+hql/P875zJplSdr8yyra+II+9dGKx867lS9jSHWDThUupLoFRPjhTO001fuqr7YufMZUq3zV8d4nI6nzuI59GJqPcv3eQ3v4gw5Ozxc6banxct76TG7s6ObetvoA9nD+PCI01zij/VLl28pX8zJKqGVN8CjX0+7SI/B6wG/hTVR2b60kicgtwC8CqVasWpWPJlPL4oWP09g3y+KETR/mXrmympyvA2y9cWvBkZfNV5ZtdtXO6ZaX5Sn5mSdWMKU6FCP7/AHwVUPf33wIfn+uJqroV2ArOOv9sd5RNSufBiQj39Qe5b+/gCTl2Wur8M6P8UkkHkD6B21Tjn/fa/HwlP7OkasYUp0UP/qo6lL4tIt8CtuVjP/NJ6ZxIpvjVwDG29wV58uUxMj9dNp7bQk93gCvOb8NfIuUF0yURz+YEbr6Sn1lSNWOK06IHfxEJqGrQvfs+YG8+9nO6lM7LW2vZ3h/k/r2DjIVmi5231Vdx/QZnlB9YsvgJ4LKt4ZtWV+WjqXZhhc/zlfzMkqoZU5zyvdTzu8BmYKmIHAG+DGwWkUtxpn1eBm7Nx75PHnGmVIknU+wPHuej335ipt0jcPl5rfR0BXjLmsIVO8+mhi845Rsbqn001fpz8s0kX8nPLKmaMcUp36t9PjRH87fzuc+09IjTK8LIVJSJcJyMbAu0N1RzY1cnN2zopKOpZjG6dFpnquGbVu330lTjo+EMJ3Czla/kZ5ZUzZjiVLYLvW/dtIYv/KiPoYnoCe3rAk185C2ruGx1a1Fd2HSqGr6DE+GzOoF7Njav7chLUM7X6xpjzl7ZBv/Nazv47+/r4ve/8xSJZIr2xho+fsVq3rV+WaG7NqfMGr5p0USKlS11rGqtK6oPKmNM6Svb4A9w1SXL+Nln30EilaLYM1ffdNlK7thxkHA8SV2Vl1gyBQh/8M4LLPAbY3KurIM/wMrWOieff5FH/7de0EZdtZfvPP4qr4+HbW7cGJNXZR/8i13mCdxz2+p5z6XLC90lY0wFsOBfAOnqWE21PkuhbIwpCAv+iyidZ6ehyqpjGWMKy4J/ni3WMk1jjMmGBf888Xs9NNX4aajx2WodY0zRseCfY1YoxRhTCixC5YCIk2dnSe2pC6UYY0wxseC/ACJOErbmuiqb2jHGlBQL/mchPdJvqfPjK5Fc/8YYk8mCfxbErYPbXGtB3xhT2iz4z8NCKmQZY0wxsuB/GjV+L0tqbeWOMab8WFSbQ727cscuyjLGlKu8TlyLyD+JyLCI7M1oaxWRh0TkoPu7JZ99yEZtlZdzmmtZ1lRjgd8YU9byfdbyLuD6k9q+CDysqhcCD7v3C6rK5yGwpJbAkloL+saYipDX4K+qu4DRk5p/G7jbvX038N589uF0vB6hraGaFS111FZZ0DfGVI5CzPkvU9Wge3sQOGVdRRG5BbgFYNWqVTnrgNcjNNX4aaq11TvGmMpU0MXqqqrAKUtsqepWVd2oqhvb29sXvD+fx0NrfRUrW+poqberco0xlasQI/8hEQmoalBEAsBwvndY5fPQUO1UyxKxgG+MMYUY+d8L3Ozevhn4Sb53GFhSS2ON3wK/Mca48r3U87vAY8DFInJERD4BfA24RkQOAu9y7xtjjFlEeZ32UdUPneKhq/O5X2OMMadn2cmMMaYCWfA3xpgKZMHfGGMqkAV/Y4ypQBb8jTGmAlnwN8aYCmTB3xhjKpA46XWKn4iMAK8Uuh8LsBQ4WuhO5IEdV+kp12Oz45rbuar6G8nRSib4lzoR2a2qGwvdj1yz4yo95XpsdlzZsWkfY4ypQBb8jTGmAlnwXzxbC92BPLHjKj3lemx2XFmwOX9jjKlANvI3xpgKZMHfGGMqkAX/BRKR60XkeRF5UUS+eIrnfFBE9ovIPhH594z2pIg84/7cu3i9np8zHZuIfCOj/y+IyHjGYzeLyEH35+aTty2kBR5X0f7N5nFcq0Tk5yLytIj0iciNGY99yd3ueRG5bnF7fmZne2wislpEwhl/s/+z+L0/tXkc17ki8rB7TDtFZEXGYwv7P6aq9nOWP4AXeAlYA1QBzwLrTnrOhcDTQIt7vyPjsalCH8NCju2k5/8h8E/u7VZgwP3d4t5uKfQxLfS4ivlvNs/34lbg993b64CXM24/C1QD57mv4y30MeXo2FYDewt9DAs4ru8DN7u3rwL+1b294P9jNvJfmMuBF1V1QFVjwD3Ab5/0nE8Cf6+qYwCqmveC9Tkyn2PL9CHgu+7t64CHVHXUPe6HgOvz2tv5W8hxFbP5HJcCTe7tJcDr7u3fBu5R1aiqHgJedF+vWCzk2IrZfI5rHbDDvf3zjMcX/H/Mgv/CLAcOZ9w/4rZlugi4SEQeFZFfi0jmH6hGRHa77e/Nd2ezNJ9jA5yvpjgjxvSbdN7bFsBCjguK9282n+P6CvARETkCbMf5VjPfbQtpIccGcJ47HfSIiLw9rz3NznyO61ng/e7t9wGNItI2z21Py4J//vlwpn4244wivyUize5j56pz2fbvAt8UkfML08UFuwn4gaomC92RHJvruEr5b/Yh4C5VXQHcCPyriJRLDDjVsQWBVar6BuCzwL+LSNNpXqfYfA54h4g8DbwDeA3Iyf+zcvnDF8prwMqM+yvctkxHgHtVNe5+pX4B58MAVX3N/T0A7ATekO8OZ2E+x5Z2EydOjWSz7WJbyHEV899sPsf1CeB7AKr6GFCDkzSsmP9esIBjc6eyjrnte3Dm2C/Ke4/n54zHpaqvq+r73Q+vv3Dbxuez7RkV+qRHKf/gjOoHcKYG0ids1p/0nOuBu93bS3G+qrXhnKSpzmg/yGlOPBbjsbnPWwu8jHvBoNvWChxyj7HFvd1a6GPKwXEV7d9snu/F+4CPubcvwZkXF2A9J57wHaC4Tvgu5Nja08eCc2L1tVJ6L7rvM497+6+A293bC/4/VvB/gFL/wfmK+QLOiOIv3Lbbgfe4twX4O2A/0A/c5LZf4d5/1v39iUIfS7bH5t7/CvC1Obb9OM6JwxeB/1roY8nFcRX732we78V1wKNu/58Brs3Y9i/c7Z4Hbij0seTq2ID/Auxz254C3l3oY8nyuD6AM8h4AfhH3MGH+9iC/o9ZegdjjKlANudvjDEVyIK/McZUIAv+xhhTgSz4G2NMBbLgb4wxFciCvzHGVCAL/mZRZKRC3isiP81IcXGq539FRD53hue8V0TWZdy/XUTelcM++0Xka27K3KdE5DERuSFXr79QIrJZRK4odD9MabLgbxZLWFUvVdUNwCjwBzl4zffiXNwDgKrepqo/y8Hrpn0VCAAbVPWN7v4ac/j6C7UZ58IzY7Jmwd8UwmO4GQhF5HwRuV9E9ojIL0Rk7clPFpFPisiTIvKsiPxQROrcEe97gL9xv1GcLyJ3icgH3AIZ38/YfrOIbHNvX+uO4J8Ske+LSMNcHRSROpx03H+oqlEAVR1S1e+5j39IRPrdbzJ/nbHdlIj8jTiFe34mIpe7RTgGROQ97nM+JiI/cdsPisiXM7b/T/ffYp+I3JLRfr3b52fd4h6rgU8Bf+Ie/9vd4/+fIvIrd38fyNj+8+6/YZ+I/De3rV5Eet3X3Csiv+O2f02c4kN9IvL1rP6ypnQU+vJm+6mMH9wiKDgFLL4PXO/efxi40L39ZmCHe/srwOfc220Zr/OXOAEZ4C7gAxmP3YVzObwPeBWod9v/AfgITp6UXRntXwBuO0V/u4GnT/HYOe7rt7v72gG8131McdMjAD8GHgT8wG8Bz7jtH8PJNtkG1AJ7gY3uY63u73R7m7ufw8B5Jz1n5t8o4/i/jzOoW4eTKx7gWpxiJ+I+tg3YhJP64FsZ2y9x9/c8zFz931zo94795OfHd6oPBWNyrFZEnsEZ8T8HPOSOuq8Avi8i6edVz7HtBhH5S6AZaAAeON2OVDUhIvcD7xaRHwA9wJ/hpMRdBzzq7q8K51tIti4DdqrqCICIfAcnmP4nEAPud5/XD0RVNS4i/ThVpdIeUjfbpIj8CHgbsBv4IxF5n/uclTgZYNuBXepkhUVVR0/Tt/9U1RSwX0SWuW3Xuj9Pu/cb3Nf9BfC37jeXbar6CxHxARHg2+63pW3Z/dOYUmHB3yyWsKpe6k6nPIAz538XMK6ql55h27twRtbPisjHcOa6z+Qe4NM45xd2q+qkOBH/IVX90Dy2fxFYJSJNqjoxj+enxVU1nTArBaSnjFJuYE07OamWishm4F3AW1U1JCI7cVITZyOacVsyfv93Vb3z5CeLyBtxkov9pYg8rKq3i8jlwNU436I+jVM+0JQZm/M3i0pVQ8AfAX8KhIBDIvJ/AYjjt+bYrBEIiogf+HBG+ySnPgH7CPBGnHn7e9y2XwNXisgF7v7qRWTO3O5uP78N3CEiVe7z292+PoFTYGOpiHhxCok8Mq9/gFnXiEiriNTinEh+FGfaZcwN/GuBt2T0e5OInOf2o3Uex5/pAeDj6fMbIrJcRDpE5BwgpKr/BvwN8Eb3OUtUdTvwJzjTVaYMWfA3i05Vnwb6cILmh4FPiMizOKl356qn+/8Cj+MEyAMZ7fcAnxenRN8JFbXUqb61DbjB/Y07TfMx4Lsi0ocz5fMbJ5gz/D/ACM4Uyl73dSZUNQh8Eaem6rPAHlX9ybz/ARxPAD/E+Xf4oaruxpku8onIc8DXcIJ+ut+3AD9y/53+w32NnwLvS5/wPdWOVPVB4N+Bx9zppx/gfGh0AU+403Ffxjmf0ghsc/99folT/cqUIUvpbMwic6euNqrqpwvdF1O5bORvjDEVyEb+puKJyI9xSull+oKqnnZVkTGlzIK/McZUIJv2McaYCmTB3xhjKpAFf2OMqUAW/I0xpgL9/9j6f/vzO+tXAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#This code block imports all the necessary libraries you need\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This line uses the read_excel() method in pandas to fetch the ENB2012_data.xlsx file for UCI archive\n",
        "df=pd.read_excel('https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx')\n",
        "\n",
        "# Defining the python dictionary\n",
        "column_names = {'X1':'Relative_Compactness', 'X2': 'Surface_Area', 'X3': 'Wall_Area', 'X4': 'Roof_Area', 'X5': 'Overall_Height', 'X6': 'Orientation', 'X7': 'Glazing_Area', 'X8': 'Glazing_Area_Distribution', 'Y1': 'Heating_Load', 'Y2': 'Cooling_Load'}\n",
        "\n",
        "# Renaming the columns with the .rename method in pandas\n",
        "df = df.rename(columns=column_names)\n",
        "\n",
        "# This line selects 15 samples of one independent and one dependent variable\n",
        "simple_linear_reg_df = df[[\"Relative_Compactness\", 'Cooling_Load']].sample(15, random_state=2)\n",
        "\n",
        "# Regression plot using seaborn (a visualization library)\n",
        "sns.regplot(x=\"Relative_Compactness\", y=\"Cooling_Load\", data=simple_linear_reg_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiple Linear Regression**"
      ],
      "metadata": {
        "id": "bhYWKDcXgNah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unlike simple linear regression, multiple linear regression establishes the relationship between the response variable and the predictors (usually two or more). In reality, several factors contribute to a certain outcome as opposed to just one as suggested by simple linear regression. Multiple linear regression has similar assumptions as simple linear regression and also assumes that there is no significant correlation between the predictors. While the relationship between variables can be linear, it allows for non-linear relationships that are not straight lines.\n",
        "\n"
      ],
      "metadata": {
        "id": "tw7uoAjIgpO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collinearity\n",
        "Correlation is a measure used to describe the linear relationship between two variables. Correlation values range from -1 for a perfect negative correlation (an increase in one variable causes a decrease in the other variable) to +1 for a perfect positive correlation (both variables increase or decrease together). A correlation value of 0 indicates that there is absolutely no correlation between both variables. A situation where two or more of the predictors have a strong correlation is known as multicollinearity. Since predictors are expected to be independent, when multicollinearity occurs, the correlated variables cannot independently contribute to predicting the value of the response variable. In addition, not all the predictors included are relevant in obtaining better results from the model. Adding more independent variables to the model is not always better instead, it might only make the model more complicated. To resolve this, one of the correlated predictors is selected and the other removed from the data."
      ],
      "metadata": {
        "id": "gR-P-xSGhh8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial Regression\n",
        "A polynomial regression model is considered a linear regression model that can be used when a curvilinear relationship exists between the predictors and the response variable. It can be represented as-\n",
        "\n",
        "Y = Theta Zero + Theta One X + Theta Two X Squared + ..... + Theta n X to the power n + E\n",
        "\n",
        "for a single independent variable where n is the degree of the polynomial and Y is a linear function of 𝜃.  Depending on the task and data, there might be multiple predictors in a polynomial regression model which results in more interactions in the model. As expected, the complexity in the model increases as the degree increases.\n",
        "\n",
        "Coefficients of multiple linear regression\n",
        "General notations"
      ],
      "metadata": {
        "id": "w36ZLhZah1IN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Measuring Regression Performance**"
      ],
      "metadata": {
        "id": "PNLOlS3tinxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Metrics for performance (RSS, R-Squared, RMSE, MAE etc)**\n",
        "\n",
        "How well a regression model performs can be obtained by how close the predicted value is to the ground truth. It is very important to use the appropriate metric to evaluate the performance. In this section, we discuss some examples of metrics used in evaluating regression models such as RSS, R-Squared, RMSE and MAE."
      ],
      "metadata": {
        "id": "ql7cJ2rpip7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mean Absolute Error (MAE)**\n",
        "\n",
        "MAE  is easy and intuitive such that it calculates the sum of the  average of the absolute error between the predicted values and the true values. Since the absolute difference is taken, this metric does not consider direction. However, because the absolute difference is obtained, it is unable to give information about the model overshooting or undershooting. The smaller the MAE is, the better the model. Therefore, if the MAE is 0, the model is perfect and accurately predicts results which is almost impossible.  The mean absolute error is more robust to outliers."
      ],
      "metadata": {
        "id": "gOlj3lrUjEwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Firstly, we normalise our dataset to a common scale using the min max scaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "normalised_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "features_df = normalised_df.drop(columns=['Heating_Load', 'Cooling_Load'])\n",
        "heating_target = normalised_df['Heating_Load']\n",
        "\n",
        "#Now, we split our dataset into the training and testing dataset. Recall that we\n",
        "# had earlier segmented the features and target variables.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(features_df, heating_target, test_size=0.3, random_state=1)\n",
        "\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "#Fit the model to the training dataset\n",
        "\n",
        "linear_model.fit(x_train, y_train)\n",
        "\n",
        "#Obtain predictions\n",
        "\n",
        "predicted_values = linear_model.predict(x_test)\n",
        "\n",
        "#MAE\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y_test, predicted_values)\n",
        "round(mae, 3) \n",
        "\n",
        "#prints 0.063"
      ],
      "metadata": {
        "id": "03yd5MOIgQmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfb32051-f91b-421b-e91b-af2331bbbf29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.063"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Residual Sum of Squares (RSS)**\n",
        "\n"
      ],
      "metadata": {
        "id": "MrgVIvjSZs_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also known as the sum of squared residuals (SSR), this metric explains the variance in the representation of the dataset by the model; it measures how well the model approximates the data. A residual is the estimated error made by a model. In simpler terms, it is the difference between the nth true value and the nth predicted value by the model. RSS is the sum of the square of errors between the residuals in a model. The lower the RSS, the better the model’s estimations and vice versa."
      ],
      "metadata": {
        "id": "yC1kNkxmZve1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "rss = np.sum(np.square(y_test - predicted_values))\n",
        "round(rss, 3) \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx3zF22gaBZA",
        "outputId": "2c00664c-9b4f-40bb-d7ff-30810b76294b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.823"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Root Mean Square Error (RMSE)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "rmse = np.sqrt(mean_squared_error(y_test, predicted_values))\n",
        "round(rmse, 3) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itsgnYFoaRqD",
        "outputId": "c672963e-ec21-4802-b311-bf4ffd1792be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.089"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R-Squared **\n",
        "\n",
        "Also known as the coefficient of determination, r-squared is a metric used in regression to determine the goodness of fit of the model. With values ranging from 0 to 1, It gives information on the percentage of the response variable  explained by the model. Mostly, the higher the value, the better the model however, this is not necessarily always true."
      ],
      "metadata": {
        "id": "N_PzCrfUabGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score = r2_score(y_test, predicted_values)\n",
        "round(r2_score, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajd4CcPmam19",
        "outputId": "d90f53f9-312b-4190-f46d-3892107d08fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.893"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model complexity, Underfitting and Overfitting**\n",
        "\n",
        "Model complexity refers to the number of input features used to train a model and the algorithmic learning complexity. An overly complex model can be difficult to interpret, prone to overfitting and also require more computing. When creating models, it is imperative for the model to generalise well enough to make reasonable predictions on new and unseen data. An overfit model will perform well on the training data and poorly on unseen data. While a model is required to learn the actual relationship of the variables in the training set, an overfit model memorises the training set, fits the noise, outliers and irrelevant information, then makes predictions based on this noise which is incorrect. On the other hand, when a model is too simple, it can be as a result of having very few features not sufficient enough to learn details and relationships in the data.  In a later section, we will discuss methods that can be used to achieve optimal and acceptable model complexities while avoiding overfitting and underfitting. \n",
        "\n",
        "**The Bias-Variance Tradeoff**\n",
        "\n",
        "Bias and variance are common occurrences in machine learning and there is a constant struggle to achieve low bias and variance. Bias is a measure of correctness of a model i.e. how far off is a model from being correct? While high bias results in an increase in the error by making assumptions which prevent the model from capturing relevant relationships between the predictors and response variable, low bias gives lower error and also prevents underfitting by capturing important relationships. On the other hand, variance tells how much the values estimated by a model will vary across different training data. When the variance is low, it means that there is only a small change in the estimate of the model with  new training  data. A high variance causes overfitting such that the changes in estimates obtained with new training data is large because the model is so complex that it has now learnt patterns from one training data such that it cannot generalise to other training sets. While it is essential to obtain low bias and low variance, it is almost impossible to achieve this simultaneously which is where the ‘bias-variance tradeoff’ occurs."
      ],
      "metadata": {
        "id": "W2hrDghha8JO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Penalization Methods**\n",
        "\n",
        "Regularization is a method used to make complex models simpler by penalising coefficients to reduce their magnitude, variance in the training set and in turn, reduce overfitting in the model. Regularization occurs by shrinking the coefficients in the model towards zero such that the complexity term added to the model will result in a bigger loss for models with a higher complexity . There are two types of regression techniques such as Ridge and Lasso regression.\n",
        "\n",
        "**Ridge Regression**\n",
        "\n",
        "Also known as L2 Regularisation, this is a technique that uses a penalty term to shrink the magnitude of coefficients towards zero without eliminating them. The shrinkage prevents overfitting caused by the complexity of the model or  collinearity. It includes the square magnitude of the coefficients to the loss function as the penalty term.  If the error is defined as the square of residual, when a L2 regularization term is added, the  result is the equation below.\n",
        "\n"
      ],
      "metadata": {
        "id": "84UW86wmeHqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "ridge_reg = Ridge(alpha=0.5)\n",
        "ridge_reg.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3JuGBiO-BhR",
        "outputId": "1efe2363-be60-4e57-fa5f-d95101c4b6c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Selection and Lasso Regression**\n",
        "\n",
        "Some datasets can be high dimensional with a very high number of features and some of them not contributing towards predicting the response variable. As a result, it becomes more computationally expensive to train a model and can also introduce noise causing the model to perform poorly. The process of selecting significant features that contribute the most in obtaining high performing models is known as feature selection. Lasso regression (Least Absolute Shrinkage and Selection Operator) reduces overfitting of the dataset by penalising the coefficients such that some coefficients are shrunk to zero and, indirectly performs feature selection by selecting only a subset of features leaving only relevant variables that minimize prediction errors. By using L1 regularisation, it includes the absolute value of the magnitude to the loss function. The application of L1 regularisation (Lasso regression)  results in simpler and sparse models that allow for better interpretation. Although lasso regression helps prevent overfitting, one major limitation is that it does not consider other factors when eliminating predictors. For example, it arbitrarily  eliminates a variable from a correlated pair which might not be a good rational from a human perspective. "
      ],
      "metadata": {
        "id": "UrF9R_zcFgmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "lasso_reg = Lasso(alpha=0.001)\n",
        "lasso_reg.fit(x_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of7gbWshH3wD",
        "outputId": "435b59b1-59a6-4ec9-ecba-74a5f7248a80"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=0.001)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing the effects of regularisation\n",
        "\n",
        "def get_weights_df(model, feat, col_name):\n",
        "\n",
        "  # This function returns the weight of every feature\n",
        "  weights = pd.Series(model.coef_, feat.columns).sort_values()\n",
        "  weights_df = pd.DataFrame(weights).reset_index()\n",
        "  weights_df.columns = ['Features', col_name]\n",
        "  weights_df[col_name].round(3)\n",
        "  return weights_df"
      ],
      "metadata": {
        "id": "-DTMt5hfKdQF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model_weights = get_weights_df(linear_model, x_train, 'Linear_Model_Weight')\n",
        "ridge_weights_df = get_weights_df(ridge_reg, x_train, 'Ridge_Weight')\n",
        "lasso_weights_df = get_weights_df(lasso_reg, x_train, 'Lasso_weight')\n",
        "\n",
        "\n",
        "final_weights = pd.merge(linear_model_weights, ridge_weights_df, on='Features')\n",
        "final_weights = pd.merge(final_weights, lasso_weights_df, on='Features')\n",
        "final_weights\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "DELYXpPWLHiV",
        "outputId": "939420dd-5b4e-49f7-860a-5091394ef01d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Features  Linear_Model_Weight  Ridge_Weight  Lasso_weight\n",
              "0               Surface_Area        -6.387091e+12     -0.062275      0.000000\n",
              "1       Relative_Compactness        -6.064125e-01     -0.283471     -0.027719\n",
              "2                Orientation        -2.822876e-03      0.003369      0.000000\n",
              "3  Glazing_Area_Distribution         1.913548e-02      0.029088      0.021431\n",
              "4               Glazing_Area         2.295933e-01      0.212449      0.206132\n",
              "5             Overall_Height         3.852539e-01      0.442467      0.463482\n",
              "6                  Wall_Area         3.725803e+12      0.103061      0.200087\n",
              "7                  Roof_Area         4.790318e+12     -0.163192     -0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8804895-7b89-4b3d-a8db-1e64d1dd0faf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Features</th>\n",
              "      <th>Linear_Model_Weight</th>\n",
              "      <th>Ridge_Weight</th>\n",
              "      <th>Lasso_weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Surface_Area</td>\n",
              "      <td>-6.387091e+12</td>\n",
              "      <td>-0.062275</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Relative_Compactness</td>\n",
              "      <td>-6.064125e-01</td>\n",
              "      <td>-0.283471</td>\n",
              "      <td>-0.027719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Orientation</td>\n",
              "      <td>-2.822876e-03</td>\n",
              "      <td>0.003369</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Glazing_Area_Distribution</td>\n",
              "      <td>1.913548e-02</td>\n",
              "      <td>0.029088</td>\n",
              "      <td>0.021431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Glazing_Area</td>\n",
              "      <td>2.295933e-01</td>\n",
              "      <td>0.212449</td>\n",
              "      <td>0.206132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Overall_Height</td>\n",
              "      <td>3.852539e-01</td>\n",
              "      <td>0.442467</td>\n",
              "      <td>0.463482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Wall_Area</td>\n",
              "      <td>3.725803e+12</td>\n",
              "      <td>0.103061</td>\n",
              "      <td>0.200087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Roof_Area</td>\n",
              "      <td>4.790318e+12</td>\n",
              "      <td>-0.163192</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8804895-7b89-4b3d-a8db-1e64d1dd0faf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8804895-7b89-4b3d-a8db-1e64d1dd0faf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8804895-7b89-4b3d-a8db-1e64d1dd0faf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model_weights = get_weights_df(linear_model, x_train, 'Linear_Model_Weight')\n",
        "ridge_weights_df = get_weights_df(ridge_reg, x_train, 'Ridge_Weight')\n",
        "lasso_weights_df = get_weights_df(lasso_reg, x_train, 'Lasso_weight')\n",
        "\n",
        "final_weights = pd.merge(linear_model_weights, ridge_weights_df, on='Features')\n",
        "final_weights = pd.merge(final_weights, lasso_weights_df, on='Features')\n",
        "final_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "nwhPF0-PNye0",
        "outputId": "c10c78d4-30c3-4b6c-cff4-5db84eee6663"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Features  Linear_Model_Weight  Ridge_Weight  Lasso_weight\n",
              "0               Surface_Area        -6.387091e+12     -0.062275      0.000000\n",
              "1       Relative_Compactness        -6.064125e-01     -0.283471     -0.027719\n",
              "2                Orientation        -2.822876e-03      0.003369      0.000000\n",
              "3  Glazing_Area_Distribution         1.913548e-02      0.029088      0.021431\n",
              "4               Glazing_Area         2.295933e-01      0.212449      0.206132\n",
              "5             Overall_Height         3.852539e-01      0.442467      0.463482\n",
              "6                  Wall_Area         3.725803e+12      0.103061      0.200087\n",
              "7                  Roof_Area         4.790318e+12     -0.163192     -0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d4d71b5-0e02-437e-9b7d-8136798078c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Features</th>\n",
              "      <th>Linear_Model_Weight</th>\n",
              "      <th>Ridge_Weight</th>\n",
              "      <th>Lasso_weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Surface_Area</td>\n",
              "      <td>-6.387091e+12</td>\n",
              "      <td>-0.062275</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Relative_Compactness</td>\n",
              "      <td>-6.064125e-01</td>\n",
              "      <td>-0.283471</td>\n",
              "      <td>-0.027719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Orientation</td>\n",
              "      <td>-2.822876e-03</td>\n",
              "      <td>0.003369</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Glazing_Area_Distribution</td>\n",
              "      <td>1.913548e-02</td>\n",
              "      <td>0.029088</td>\n",
              "      <td>0.021431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Glazing_Area</td>\n",
              "      <td>2.295933e-01</td>\n",
              "      <td>0.212449</td>\n",
              "      <td>0.206132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Overall_Height</td>\n",
              "      <td>3.852539e-01</td>\n",
              "      <td>0.442467</td>\n",
              "      <td>0.463482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Wall_Area</td>\n",
              "      <td>3.725803e+12</td>\n",
              "      <td>0.103061</td>\n",
              "      <td>0.200087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Roof_Area</td>\n",
              "      <td>4.790318e+12</td>\n",
              "      <td>-0.163192</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d4d71b5-0e02-437e-9b7d-8136798078c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d4d71b5-0e02-437e-9b7d-8136798078c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d4d71b5-0e02-437e-9b7d-8136798078c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elastic Net Regression**\n",
        "\n",
        "This is simply a combination of the L1 and L2 penalties from ridge and lasso regression. This method arose from the need to overcome the limitations of lasso regression. It regularizes and performs feature selection simultaneously by initially finding the optimal values of the coefficients as in ridge then performs a shrinkage."
      ],
      "metadata": {
        "id": "pD4mKSjYNJc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Non-Linear Regression Methods and Other Recommendations**\n",
        "\n"
      ],
      "metadata": {
        "id": "sxcmmDDtOg2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Tuning and choosing parameters**\n",
        "\n",
        "Machine learning models are parameterized such that there has to be a search for the combination of parameters that will result in the optimal performance of the model. The parameters that define the model architecture are referred to as hyperparameters while the process of exploring a range of values is called hyperparameter tuning. It is important to note the distinction between model parameters and hyperparameters. Unlike hyperparameters, model parameters are learnt during the training phase while setting hyperparameters is exclusive of the training process. Ideally, when hyperparameter tuning is completed, the result is the best parameters for the model. Grid search and random search are two common strategies for tuning hyperparameters. "
      ],
      "metadata": {
        "id": "_77T4A5QOl9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grid Search**\n",
        "\n",
        "Grid search explores the combination of a grid of parameters such that for every combination of parameters, a model is built and evaluated then the model with the best result selected and its corresponding parameters. While it is computationally expensive, setting up a grid search is quite easy.\n",
        "\n"
      ],
      "metadata": {
        "id": "qvcsrloIQuBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Search**\n",
        "\n",
        "As opposed to grid search, random search randomly combines parameter values in the grid to build and evaluate models. It does not sequentially combine all parameters as in grid search instead, it allows for a quick exploration of the entire action space to reach optimal values.\n",
        "\n"
      ],
      "metadata": {
        "id": "v_wXqiOqQ122"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data splitting, resampling and cross validation strategy**\n",
        "\n",
        "Data splitting in data science involves setting aside a portion of the dataset for testing (out of sample or hold-out) and evaluating the performance of the model to provide unbiased results while the rest is used in fitting the model. The proportion of division is solely based on choice and sometimes, the size of the dataset. However a common practice is to split the dataset into training, validation or dev and testing sets where the validation set is used to tune the hyperparameters to select the best values for the model. Resampling involves repeatedly selecting samples from the original dataset and using these samples to obtain more information about the model. This can create different samples of the training set and another for evaluation. Cross validation is a method used to generalise and prevent overfitting in machine learning"
      ],
      "metadata": {
        "id": "pFI46Ot0RFB2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "ML_Regression_Predicting_Energy_Efficiency_of_Buildings_Hamoye_Task2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}